"""
reflection_removal.py
======================

This script demonstrates a basic pipeline for removing water‑drop or
specular reflections from a single container image using a precomputed
mask.  The algorithm follows the guidelines from the programming
assignment specification: first detect reflection regions (mask), then
remove them using OpenCV's inpainting techniques【223524787475971†L6-L19】.

The approach implemented here is as follows:

1. **Read the original image and its corresponding reflection mask.**
   The mask should be a single–channel 8‑bit image with 255 values
   indicating pixels to be corrected.  If necessary, the mask can be
   dilated slightly to ensure that halo pixels around the droplets are
   included in the inpainting region.

2. **Classify each connected component in the mask** by area.  Small
   specular highlights (e.g. single droplets) are inpainted with
   Telea's fast marching method; larger areas (e.g. streaks or bigger
   reflections) use the Navier–Stokes based method.  This per–region
   classification yields cleaner results than using a single method for
   all regions.

3. **Apply inpainting region by region.**  For each connected
   component a temporary mask is created and passed to
   ``cv2.inpaint`` along with the current working image.  The result
   of each inpaint operation updates the working image so that
   subsequent regions are inpainted on top of the already corrected
   image.

4. **Optionally perform a light blending pass** to reduce seams
   between the inpainted regions and the untouched background.  Here
   we apply a joint bilateral filter to the inpainted pixels only,
   using the original image as a guide to preserve edges.

This script operates on a single image for testing purposes.  To
process multiple images, wrap the ``process_image`` function in a
loop over your dataset.

Usage
-----
Adjust the ``IMG_PATH`` and ``MASK_PATH`` constants below to point
to your test image and its mask.  Run the script with:

```
python3 reflection_removal.py
```

The result will be written to ``RESULT_PATH``.
"""

from __future__ import annotations

import cv2
import numpy as np
from pathlib import Path


# -------------------------------------------------------------------------
# Configuration: modify these paths for your environment
# -------------------------------------------------------------------------
# Path to the original (unprocessed) image on which to remove reflections.
IMG_PATH = Path("data/images/100.png")
# Path to the reflection mask corresponding to IMG_PATH.  The mask
# should be a single–channel image with values 0 or 255.  By default we
# expect the mask generated by the waterdrop detection pipeline to
# reside in ``mask``.
MASK_PATH = Path("mask/100_waterdrop_mask.png")
# Output path for the reflection–removed image.
RESULT_PATH = Path("result/100_reflection_removed.png")


def load_images(img_path: Path, mask_path: Path) -> tuple[np.ndarray, np.ndarray]:
    """Load the input image and its corresponding mask.

    The image is loaded as a colour (BGR) image.  The mask is loaded
    as a single–channel grayscale image.  If the files cannot be
    loaded, a ``FileNotFoundError`` is raised.

    Parameters
    ----------
    img_path : pathlib.Path
        Path to the original image.
    mask_path : pathlib.Path
        Path to the reflection mask.

    Returns
    -------
    tuple
        A tuple ``(img, mask)`` where ``img`` is a BGR image and
        ``mask`` is a single–channel 8‑bit mask.
    """
    if not img_path.exists():
        raise FileNotFoundError(f"Image not found: {img_path}")
    if not mask_path.exists():
        raise FileNotFoundError(f"Mask not found: {mask_path}")
    img = cv2.imread(str(img_path), cv2.IMREAD_COLOR)
    if img is None:
        raise RuntimeError(f"Failed to load image: {img_path}")
    mask = cv2.imread(str(mask_path), cv2.IMREAD_GRAYSCALE)
    if mask is None:
        raise RuntimeError(f"Failed to load mask: {mask_path}")
    return img, mask


def dilate_mask(mask: np.ndarray, kernel_size: int = 5, iterations: int = 1) -> np.ndarray:
    """Dilate the binary mask slightly to include halo pixels.

    A small dilation helps to ensure that bright rims around the
    droplets are also removed.  An elliptical structuring element is
    used to prevent square artefacts.

    Parameters
    ----------
    mask : numpy.ndarray
        Input binary mask with values 0 or 255.
    kernel_size : int, optional
        Size of the structuring element (default is 5).
    iterations : int, optional
        Number of dilation iterations (default is 1).

    Returns
    -------
    numpy.ndarray
        Dilated binary mask.
    """
    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_size, kernel_size))
    dilated = cv2.dilate(mask, kernel, iterations=iterations)
    return dilated


def classify_components(mask: np.ndarray, small_thresh: int = 300) -> tuple[list[np.ndarray], list[np.ndarray]]:
    """Split the mask into small and large connected component masks.

    Connected components with an area less than ``small_thresh`` are
    considered small and are collected into a list.  Larger components
    are collected separately.  Each returned mask contains only one
    connected component with values 0 or 255.

    Parameters
    ----------
    mask : numpy.ndarray
        Dilated binary mask.
    small_thresh : int, optional
        Threshold on component area (pixels) to classify as small or
        large.  Defaults to 300.

    Returns
    -------
    tuple
        ``(small_masks, large_masks)`` where each element is a list of
        single–component masks.
    """
    num, labels, stats, _ = cv2.connectedComponentsWithStats(mask, connectivity=8)
    small_masks = []
    large_masks = []
    for i in range(1, num):  # skip background (label 0)
        area = stats[i, cv2.CC_STAT_AREA]
        comp_mask = (labels == i).astype(np.uint8) * 255
        if area < small_thresh:
            small_masks.append(comp_mask)
        else:
            large_masks.append(comp_mask)
    return small_masks, large_masks


def inpaint_regions(
    img: np.ndarray,
    comp_masks: list[np.ndarray],
    method: int,
    radius: float,
) -> np.ndarray:
    """Inpaint each connected component in ``comp_masks`` on ``img``.

    Parameters
    ----------
    img : numpy.ndarray
        Working image on which the regions will be inpainted.  This
        image is modified in place.
    comp_masks : list of numpy.ndarray
        List of single–component masks (0/255).  Each mask denotes a
        region to be inpainted.
    method : int
        OpenCV inpainting flag (``cv2.INPAINT_TELEA`` or
        ``cv2.INPAINT_NS``).
    radius : float
        Inpainting radius.  Determines how far neighbourhoods are
        considered for filling missing pixels.

    Returns
    -------
    numpy.ndarray
        The updated image after inpainting all components.
    """
    result = img.copy()
    for cmask in comp_masks:
        # OpenCV expects mask values of 0/255, but cv2.inpaint uses
        # non‑zero pixels, so we can pass cmask directly
        result = cv2.inpaint(result, cmask, radius, method)
    return result


def joint_bilateral_on_mask(
    img: np.ndarray,
    mask: np.ndarray,
    sigma_space: float = 2.0,
    sigma_color: float = 20.0,
) -> np.ndarray:
    """Apply a joint bilateral filter only on the masked pixels.

    A bilateral filter smooths an image while preserving edges.  A
    joint bilateral filter uses another image (the guidance image) to
    steer the smoothing.  Here we use the original image as the guide
    so that the inpainted pixels are blended to match the texture of
    the surroundings without blurring edges unnecessarily.

    Parameters
    ----------
    img : numpy.ndarray
        The inpainted image that will be smoothed.
    mask : numpy.ndarray
        Binary mask indicating where the bilateral filter should be
        applied (255=apply filter, 0=leave untouched).
    sigma_space : float, optional
        Filter sigma in the coordinate space.  A larger value means
        that more distant pixels influence each other (defaults to 2.0).
    sigma_color : float, optional
        Filter sigma in the colour space.  A larger value means that
        pixels with greater colour difference influence each other
        (defaults to 20.0).

    Returns
    -------
    numpy.ndarray
        The blended image.
    """
    # Create a mask for use in filtering: make sure it's binary 0/1
    m = (mask > 0).astype(np.uint8)
    # Create a blurred version of the image using joint bilateral
    # filtering.  We use cv2.ximgproc.jointBilateralFilter if available;
    # otherwise fall back to cv2.bilateralFilter with the image itself
    # as both source and guide.
    try:
        from cv2.ximgproc import jointBilateralFilter  # type: ignore
        guide = img  # guide image is the original inpainted image
        blurred = jointBilateralFilter(guide, img, d=5, sigmaColor=sigma_color, sigmaSpace=sigma_space)
    except Exception:
        # Fall back to standard bilateral filter
        blurred = cv2.bilateralFilter(img, d=5, sigmaColor=sigma_color, sigmaSpace=sigma_space)
    # Blend only the pixels inside the mask
    out = img.copy()
    out[m > 0] = blurred[m > 0]
    return out


def process_image(
    img_path: Path,
    mask_path: Path,
    result_path: Path,
    small_thresh: int = 300,
    dilate_kernel: int = 5,
    dilate_iter: int = 1,
) -> None:
    """Load an image and mask, remove reflections, and save the result.

    This function orchestrates the reflection removal pipeline: load
    images, dilate the mask, classify components, apply Telea and
    Navier–Stokes inpainting to small and large regions respectively,
    optionally perform blending, and write the result to disk.

    Parameters
    ----------
    img_path : pathlib.Path
        Path to the original image.
    mask_path : pathlib.Path
        Path to the reflection mask.
    result_path : pathlib.Path
        Path where the processed image will be saved.  Parent
        directories are created if necessary.
    small_thresh : int, optional
        Area threshold distinguishing small and large components.  The
        default (300) was chosen empirically for the test data.
    dilate_kernel : int, optional
        Size of the dilation kernel used to expand the mask (default 5).
    dilate_iter : int, optional
        Number of dilation iterations (default 1).
    """
    img, mask = load_images(img_path, mask_path)
    # Dilate mask to include halo
    dilated = dilate_mask(mask, kernel_size=dilate_kernel, iterations=dilate_iter)
    # Classify connected components into small and large
    small_masks, large_masks = classify_components(dilated, small_thresh=small_thresh)
    # Inpaint small components using Telea (fast marching)
    result = img.copy()
    if small_masks:
        result = inpaint_regions(result, small_masks, cv2.INPAINT_TELEA, radius=4.0)
    # Inpaint large components using Navier–Stokes
    if large_masks:
        result = inpaint_regions(result, large_masks, cv2.INPAINT_NS, radius=8.0)
    # Light blending on all inpainted regions (optional)
    # Use the dilated mask as the region to smooth
    blended = joint_bilateral_on_mask(result, dilated, sigma_space=2.5, sigma_color=25.0)
    # Ensure output directory exists
    result_path.parent.mkdir(parents=True, exist_ok=True)
    # Write result
    cv2.imwrite(str(result_path), blended)
    print(f"Reflection removed image saved to {result_path}")


def main() -> None:
    process_image(IMG_PATH, MASK_PATH, RESULT_PATH)


if __name__ == "__main__":
    main()